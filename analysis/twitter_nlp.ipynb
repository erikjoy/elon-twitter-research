{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Score = Tweet sentiment * Tweet relevance\n",
    "### Tweet sentiment score = (-1, 1)\n",
    "### Tweet relevance = sum of the salience scores of the specified keywords\n",
    "### Twitter data per day = average of all tweet scores OR sum of all tweet scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from definitions import GOOGLE_CRED_PATH, DATA_DIR\n",
    "from google.cloud import language_v1\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(GOOGLE_CRED_PATH)\n",
    "client = language_v1.LanguageServiceClient(credentials=credentials)\n",
    "document_type = language_v1.Document.Type.PLAIN_TEXT\n",
    "encoding_type = language_v1.EncodingType.UTF8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv(DATA_DIR + '/elonmusk_new.csv')\n",
    "tweet_df = pd.DataFrame({'Sentiment': [], 'Magnitude': [], 'Entity to Salience': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in twitter_data.tweet:\n",
    "    document = {'content': tweet, 'type_': document_type}\n",
    "    request = {'document': document, 'encoding_type': encoding_type}\n",
    "    entity_dict = {}\n",
    "\n",
    "    try:\n",
    "        sentiment_response = client.analyze_sentiment(request=request)\n",
    "    except:\n",
    "        sentiment = magnitude = float('nan')\n",
    "    else:\n",
    "        sentiment = sentiment_response.document_sentiment.score\n",
    "        magnitude = sentiment_response.document_sentiment.magnitude\n",
    "\n",
    "        entity_response = client.analyze_entities(request=request)\n",
    "        for entity in entity_response.entities:\n",
    "            entity_dict[entity.name] = entity.salience\n",
    "\n",
    "    tweet_results = {'Sentiment': sentiment, 'Magnitude': magnitude, 'Entity to Salience': entity_dict}\n",
    "    tweet_df = tweet_df.append(tweet_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[['Sentiment', 'Magnitude', 'Entity to Salience']] = tweet_df\n",
    "twitter_data.to_csv(DATA_DIR + '/twitter.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}